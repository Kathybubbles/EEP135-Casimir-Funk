{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    " # Merging Datasets, Cleaning and Filtering Dataframe, & Diet Function -> Deliverable A: Data on Prices for Different Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and cleaning data\n",
    "def drop_nan_columns(df):\n",
    "    # Drop columns where all values are NaN\n",
    "    df_cleaned = df.dropna(axis=1, how='all')\n",
    "    return df_cleaned\n",
    "\n",
    "# USDA Data for Prices\n",
    "usda_data = pd.read_csv(\"USDA-305tj(Sheet1).csv\")\n",
    "# Trader Joes Data for Ingredients\n",
    "tj_data = pd.read_csv('trader_joes.csv')\n",
    "tj_data.rename(columns={\"gtin_upc\":\"GTIN/UPC\"}, inplace=True)\n",
    "\n",
    "# Merging data\n",
    "merged_data = pd.merge(usda_data, tj_data, how = 'outer', on = 'GTIN/UPC' )\n",
    "merged_data = drop_nan_columns(merged_data)\n",
    "\n",
    "# Data of complete pricing\n",
    "completed_prices = pd.read_csv(\"EEP153_COMPLETED_PRICES.csv\")\n",
    "completed_prices['GTIN/UPC'] = completed_prices['GTIN/UPC'].astype(int)\n",
    "\n",
    "# Dropping unneeded columns and duplicates\n",
    "not_needed = ['branded_food_category', 'data_source', 'modified_date',\n",
    "            'available_date', 'market_country', 'Unnamed: 0', 'brand_owner', 'Market Country',\n",
    "            'brand_name', 'Brand Owner', 'Brand']\n",
    "\n",
    "merged_data_drop = merged_data.drop(not_needed, axis = 1)\n",
    "merged_data_drop.drop_duplicates()\n",
    "\n",
    "# Setting index, and cleaning data\n",
    "merged_data_drop = merged_data_drop.set_index('Name')\n",
    "merged_data_clean =  merged_data_drop[merged_data_drop.index.notna()]\n",
    "merged_data_clean = merged_data_clean.reset_index().drop(['Price', 'Name'], axis = 1)\n",
    "merged_data_clean = merged_data_clean[~merged_data_clean['GTIN/UPC'].duplicated(keep='first')]\n",
    "\n",
    "# Final data frame, before cleaning\n",
    "final_data = pd.merge(completed_prices, merged_data_clean, on = 'GTIN/UPC', how = 'left')\n",
    "\n",
    "# Cleaning Data Frame\n",
    "final_data['ingredients'] = final_data.apply(\n",
    "    lambda row: f\"{row['ingredients_x']}, {row['ingredients_y']}\" if pd.notna(row['ingredients_x']) and pd.notna(row['ingredients_y']) \n",
    "    else row['ingredients_x'] if pd.notna(row['ingredients_x']) \n",
    "    else row['ingredients_y'], axis=1\n",
    ")\n",
    "\n",
    "# Filling in missing ingredients\n",
    "fill_ingredients = ['WHEAT FLOUR, SUGAR, SALT, BARLEY MALT SYRUP',\\\n",
    "                     'POPCORN, SUNFLOWER OIL, SUGAR, SALT', 'SOLID WHITE TUNA, WATER, SALT']\n",
    "\n",
    "final_data.loc[final_data['ingredients'].isna(), 'ingredients'] = fill_ingredients\n",
    "final_data = final_data.drop(['ingredients_x', 'ingredients_y'], axis = 1).set_index('Name')\n",
    "\n",
    "# Inserting missing fdc id\n",
    "insert_fdc = [2084934, 2008228, 2699210, 363148, 2039889, 2089618 ]\n",
    "final_data.loc[final_data['fdc_id'].isna(), 'fdc_id'] = insert_fdc\n",
    "\n",
    "# Replacing last ingredient\n",
    "final_data.loc[final_data.index[-1], 'ingredients'] = \"OLD FASHIONED ROLLED OATS - QUAKER, HONEY, RAW WALNUTS, ALMONDS, RAW,\\\n",
    "                                                      LIGHT BROWN SUGAR - DOMINO, COCONUT FLAKES UNSWEETENED, PURE VANILLA EXTRACT,\\\n",
    "                                                          TRADER JOE'S COCONUT OIL, SALT, TABLE\"\n",
    "\n",
    "# Final dataset\n",
    "final_data\n",
    "# Converting to CSV\n",
    "final_data.to_csv('final_data_tj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out dataframe depending on certain strings\n",
    "def remove_rows(df, column_name, search_strings):\n",
    "    # Convert all values in the specified column to strings\n",
    "    df[column_name] = df[column_name].apply(lambda x: str(x) if x is not None else \"\")\n",
    "    # Create a regex pattern to match any of the search strings as whole words\n",
    "    search_pattern = r'|'.join([r'\\b' + re.escape(search_string) + r'\\b' for search_string in search_strings])\n",
    "    # Filtering out rows where the column contains any of the search strings\n",
    "    df_filtered = df[~df[column_name].str.contains(search_pattern, case=False, na=False, regex=True)]\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "# Function to keep certain values depending on certain strings\n",
    "def keep_rows(df, column_name, search_strings):\n",
    "    # Converts all values to strings\n",
    "    df[column_name] = df[column_name].apply(lambda x: str(x) if x is not None else \"\")\n",
    "    # Create a regex pattern for exact matches\n",
    "    search_pattern = r'|'.join([r'\\b' + re.escape(search_string) + r'\\b' for search_string in search_strings])\n",
    "    # Filter rows where the column matches any of the exact strings in search_strings\n",
    "    filtered_df = df[df[column_name].str.contains(search_pattern, case=False, na=False)]\n",
    "    return filtered_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category for Carnivore Diet\n",
    "carnivore_category = ['Canned Seafood', 'Canned Meat','Cream','Cheese', 'Other Meats','Canned Tuna',\n",
    "              \"Pepperoni, Salami & Cold Cuts\"]\n",
    "# Ingredients for Carnivore Diet\n",
    "carnivore_ingredients = ['CHICKEN', 'BEEF', 'HAM', 'PORK', 'FISH', 'TURKEY', 'SALMON', 'TUNA',\n",
    "                  'SHRIMP', 'LOBSTER', 'CRAB', 'SCALLOPS', 'CLAMS', 'OYSTERS', 'CREAM', 'EGG', 'EGGS']\n",
    "# Names to drop\n",
    "drop_name = ['PICKLE', 'WHEAT', 'CANE']\n",
    "\n",
    "# Filtering for final Carnivore DF\n",
    "first_filter = keep_rows(final_data, 'ingredients', carnivore_ingredients)\n",
    "second_filter = keep_rows(first_filter.copy(), 'Branded Food Category', carnivore_category)\n",
    "third_filter = remove_rows(second_filter, 'ingredients', drop_name)\n",
    "\n",
    "# Converting to CSV\n",
    "third_filter.to_csv('carnivore_final_tj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vegetarian Dataframe\n",
    "meats_and_fish = ['CHICKEN', 'BEEF', 'HAM', 'PORK', 'FISH', 'TURKEY', 'SALMON', 'TUNA',\n",
    "                  'SHRIMP', 'LOBSTER', 'CRAB', 'SCALLOPS', 'CLAMS', 'OYSTERS', 'GELATINE']\n",
    "veg_df = remove_rows(final_data, 'ingredients', meats_and_fish)\n",
    "# Converting to CSV\n",
    "veg_df.to_csv('vegetarian_tj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vegan Dataframe\n",
    "animal_products = ['CHICKEN', 'BEEF', 'HAM', 'PORK', 'FISH','TURKEY', 'SALMON', 'TUNA',\n",
    "                    'MILK', 'BUTTER', 'EGG', 'EGGS', 'HONEY', 'CHEESE', 'YOGURT', 'CREAM', 'GELATINE',\n",
    "                    'SHRIMP', 'LOBSTER', 'CRAB', 'SCALLOPS', 'CLAMS', 'OYSTERS']\n",
    "\n",
    "vegan_df = remove_rows(final_data, 'ingredients', animal_products)\n",
    "# Converting to CSV\n",
    "vegan_df.to_csv('vegan_tj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carnivore Dataframe\n",
    "carnivore_df = keep_rows(final_data, 'ingredients', animal_products)\n",
    "# Converting to CSV\n",
    "carnivore_df.to_csv('carnivore_tj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allergen Free Dataframe\n",
    "allergen_free = ['MILK', 'BUTTER', 'CHEESE', 'YOGURT', 'CREAM', \n",
    "                     'EGG', 'EGGS', \n",
    "                     'WHEAT', 'BARLEY', 'RYE', 'MALT', 'OATS', \n",
    "                     'PEANUTS', 'ALMONDS', 'CASHEWS', 'WALNUTS', 'PISTACHIOS', 'PECANS', 'HAZELNUTS', \n",
    "                     'SOY', 'SOYBEAN', 'SOY LECITHIN', 'TOFU', \n",
    "                     'SHRIMP', 'LOBSTER', 'CRAB', 'SCALLOPS', 'CLAMS', 'OYSTERS']\n",
    "\n",
    "allergen_free_df = remove_rows(final_data, 'ingredients', allergen_free)\n",
    "\n",
    "# Converting to CSV\n",
    "allergen_free_df.to_csv('allergen_free_tj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High Fat and Low Carb Diet DF\n",
    "\n",
    "hflc_ingredients = ['CHICKEN', 'BEEF', 'HAM', 'PORK', 'FISH','TURKEY', 'SALMON', 'TUNA',\n",
    "                    'MILK', 'BUTTER', 'EGG', 'EGGS', 'HONEY', 'CHEESE', 'YOGURT', 'CREAM', 'GELATINE',\n",
    "                    'SHRIMP', 'LOBSTER', 'CRAB', 'SCALLOPS', 'CLAMS', 'OYSTERS', 'OIL', 'BERRIES',\n",
    "                    'AVOCADO', 'PEANUTS', 'ALMONDS', 'CASHEWS', 'WALNUTS', 'PISTACHIOS', 'PECANS', 'HAZELNUTS']\n",
    "\n",
    "hflc_df = keep_rows(final_data, 'ingredients', hflc_ingredients)\n",
    "\n",
    "htlc_categories = ['Chocolate', 'Cereal', 'Chips, Pretzels & Snacks', 'Crackers & Biscotti', 'Honey', 'Other Soups',\n",
    "                    'French Fries', 'Potatoes & Onion Rings', 'Breads & Buns', 'Ice Cream & Frozen Yogurt', 'Flavored Snack Crackers',\n",
    "                    'Cakes, Cupcakes, Snack Cakes',  'Alcohol' , 'Cookies & Biscuits', 'Dips & Salsa', 'Wholesome Snacks', 'Rice',\n",
    "                   'Cake, Cookie & Cupcake Mixes', 'Chili & Stew', \"Frozen Appetizers & Hors D'oeuvres\"]\n",
    "\n",
    "hflc = remove_rows(hflc_df.copy(), 'Branded Food Category', htlc_categories)\n",
    "# Converting to CSV\n",
    "hflc.to_csv('hflc_tj.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
